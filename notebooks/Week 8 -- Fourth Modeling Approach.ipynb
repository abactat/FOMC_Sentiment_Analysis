{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d5074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from mord import OrdinalRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "419d59cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download the dataset. Status code: 404\n",
      "Failed to download the dataset. Status code: 404\n",
      "Failed to download the dataset. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "# The URL of the raw dataset on GitHub\n",
    "url = \"https://raw.githubusercontent.com/abactat/BC-Project/main/data/processed/train_data.csv?token=GHSAT0AAAAAACC4ZCNKRKQBWCGNKARGMRZ2ZGRO5TA\"\n",
    "\n",
    "# Send an HTTP GET request to fetch the content of the raw dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200 means success)\n",
    "if response.status_code == 200:\n",
    "    # Read the content as a pandas DataFrame and assign it to the 'train' variable\n",
    "    train = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Dataset downloaded and loaded into 'train' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")\n",
    "    \n",
    "# The URL of the raw dataset on GitHub\n",
    "url = \"https://raw.githubusercontent.com/abactat/BC-Project/main/data/processed/val_data.csv?token=GHSAT0AAAAAACC4ZCNL6CLEYWQ7I647KVRWZGRO57A\"\n",
    "\n",
    "# Send an HTTP GET request to fetch the content of the raw dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200 means success)\n",
    "if response.status_code == 200:\n",
    "    # Read the content as a pandas DataFrame and assign it to the 'valid' variable\n",
    "    valid = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Dataset downloaded and loaded into 'valid' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")\n",
    "    \n",
    "# The URL of the raw dataset on GitHub\n",
    "url = \"https://raw.githubusercontent.com/abactat/BC-Project/main/data/processed/test_data.csv?token=GHSAT0AAAAAACC4ZCNKRR63P6ASKCCXTCAWZGRO6HQ\"\n",
    "\n",
    "# Send an HTTP GET request to fetch the content of the raw dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200 means success)\n",
    "if response.status_code == 200:\n",
    "    # Read the content as a pandas DataFrame and assign it to the 'train' variable\n",
    "    test = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Dataset downloaded and loaded into 'test' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b9863",
   "metadata": {},
   "source": [
    "###Preprocess the data with variables, and function for converting predicted values into magnitude of 25 basis points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e3334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert variables to numeric in the train dataset\n",
    "variables_to_convert = train.columns.drop('Date')\n",
    "train[variables_to_convert] = train[variables_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert variables to numeric in the valid dataset\n",
    "valid[variables_to_convert] = valid[variables_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Prepare the data for the model\n",
    "X_train = train.drop(columns=['Difference', 'Increase', 'Decrease', 'Date'])\n",
    "y_train = train['Difference']  # Use the 'Difference' variable as the target\n",
    "\n",
    "X_valid = valid.drop(columns=['Difference', 'Increase', 'Decrease', 'Date'])\n",
    "y_valid = valid['Difference']  # Use the 'Difference' variable as the target\n",
    "\n",
    "possible_values = [-1.00, -0.75, -0.50, -0.25, 0.00, 0.25, 0.50, 0.75, 1.00]\n",
    "\n",
    "def round_to_nearest(value, possible_values):\n",
    "    return min(possible_values, key=lambda x: abs(x - value))\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(y_true)\n",
    "    \n",
    "    for true_val, pred_val in zip(y_true, y_pred):\n",
    "        if true_val == pred_val:\n",
    "            correct_predictions += 1\n",
    "            \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a4c64",
   "metadata": {},
   "source": [
    "###Ordinal Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9096d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and scale the independent variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Initialize and train the ordinal logistic regression model\n",
    "ordinal_model = OrdinalRidge()\n",
    "ordinal_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = ordinal_model.predict(X_valid_scaled)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = ordinal_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af368b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |      0.0371094 |        0.0885417 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |      0.192638  |        0.29756   |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |      0.0731315 |       -0.36227   |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |     -0.903569  |        1.41776   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |      0.708333  |        0.541667  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438c762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and scale the independent variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Initialize and train the ordinal logistic regression model\n",
    "ordinal_model = OrdinalRidge()\n",
    "ordinal_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = ordinal_model.predict(X_valid_scaled)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = ordinal_model.predict(X_train_scaled)\n",
    "\n",
    "# Get the initial model performance (MSE) on the validation set\n",
    "best_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Initialize the list of selected features with all features\n",
    "selected_features = list(range(X_train_scaled.shape[1]))\n",
    "\n",
    "# Perform reverse variable selection\n",
    "while len(selected_features) > 1:\n",
    "    # Store the current MSE and feature to be removed\n",
    "    current_best_mse = best_mse\n",
    "    feature_to_remove = None\n",
    "    \n",
    "    # Iterate over each feature and remove one at a time\n",
    "    for feature in selected_features:\n",
    "        # Create a copy of the selected features with the current feature removed\n",
    "        reduced_X_train_scaled = np.delete(X_train_scaled, feature, axis=1)\n",
    "        reduced_X_valid_scaled = np.delete(X_valid_scaled, feature, axis=1)\n",
    "        \n",
    "        # Initialize and train the ordinal logistic regression model with the reduced features\n",
    "        ordinal_model = OrdinalRidge()\n",
    "        ordinal_model.fit(reduced_X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions on the validation set with the reduced features\n",
    "        y_valid_pred = ordinal_model.predict(reduced_X_valid_scaled)\n",
    "        \n",
    "        # Calculate the MSE with the reduced features\n",
    "        mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "        \n",
    "        # Check if the model performance has improved\n",
    "        if mse < current_best_mse:\n",
    "            current_best_mse = mse\n",
    "            feature_to_remove = feature\n",
    "            \n",
    "    # If removing a feature improves the model performance, update the selected features and best MSE\n",
    "    if feature_to_remove is not None:\n",
    "        selected_features.remove(feature_to_remove)\n",
    "        best_mse = current_best_mse\n",
    "    else:\n",
    "        # No feature was removed, exit the loop\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44a0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'selected_features' contains the list of best selected features\n",
    "selected_X_train = X_train_scaled[:, selected_features]\n",
    "selected_X_valid = X_valid_scaled[:, selected_features]\n",
    "\n",
    "# Initialize and train the XGBoost model with the best selected features\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(selected_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set with the best selected features\n",
    "y_train_pred = xgb_model.predict(selected_X_train)\n",
    "\n",
    "# Make predictions on the validation set with the best selected features\n",
    "y_valid_pred = xgb_model.predict(selected_X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a77236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0260417 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.161374  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.599332  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.12287   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.583333  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = selected_X_train.shape[0]\n",
    "p_train = selected_X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad606c7",
   "metadata": {},
   "source": [
    "###XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5cd80",
   "metadata": {},
   "source": [
    "###All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d69654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = xgb_model.predict(X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c98480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in selected_features: 192\n"
     ]
    }
   ],
   "source": [
    "num_variables = len(X_train)\n",
    "print(\"Number of variables in selected_features:\", num_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c1aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0286458 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.169251  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.559265  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.13516   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.541667  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd1a915",
   "metadata": {},
   "source": [
    "###Reverse Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e78e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Score: 0.708282545045338\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Evaluate initial model performance\n",
    "initial_model_score = xgb_model.score(X_valid, y_valid)\n",
    "best_model_score = initial_model_score\n",
    "best_model = xgb_model\n",
    "\n",
    "# Step 2 to 6: Reverse variable selection loop\n",
    "selected_features = list(X_train.columns)  # Assuming X_train is a DataFrame\n",
    "for feature in X_train.columns:\n",
    "    # Temporarily remove the feature\n",
    "    X_train_subset = X_train.drop(feature, axis=1)\n",
    "    X_valid_subset = X_valid.drop(feature, axis=1)\n",
    "    \n",
    "    # Retrain the model without the removed feature\n",
    "    xgb_model_subset = xgb.XGBRegressor()\n",
    "    xgb_model_subset.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Evaluate the model performance on the validation set\n",
    "    model_score = xgb_model_subset.score(X_valid_subset, y_valid)\n",
    "    \n",
    "    # Check if the model performance improved\n",
    "    if model_score > best_model_score:\n",
    "        best_model_score = model_score\n",
    "        best_model = xgb_model_subset\n",
    "        selected_features.remove(feature)\n",
    "print(\"Best Model Score:\", best_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c34ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in selected_features: 95\n"
     ]
    }
   ],
   "source": [
    "num_variables = len(selected_features)\n",
    "print(\"Number of variables in selected_features:\", num_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5560b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'selected_features' contains the list of best selected features\n",
    "selected_X_train = X_train[selected_features]\n",
    "selected_X_valid = X_valid[selected_features]\n",
    "\n",
    "# Initialize and train the XGBoost model with the best selected features\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(selected_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set with the best selected features\n",
    "y_train_pred = xgb_model.predict(selected_X_train)\n",
    "\n",
    "# Make predictions on the validation set with the best selected features\n",
    "y_valid_pred = xgb_model.predict(selected_X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c77fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0338542 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.183995  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.479132  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.15973   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.583333  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f480f5",
   "metadata": {},
   "source": [
    "###Variable selection, greater than 0.01 feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef660e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "Standardized Sentiment Score: 0.2369\n",
      "recession: 0.1237\n",
      "adverse: 0.1074\n",
      "irregular: 0.0855\n",
      "correction: 0.0642\n",
      "discontinuance: 0.0439\n",
      "CEI: 0.0305\n",
      "downward: 0.0276\n",
      "unwilling: 0.0276\n",
      "downturn: 0.0238\n",
      "tremendous: 0.0226\n",
      "Retail Sales: 0.0172\n",
      "protest: 0.0146\n",
      "concern: 0.0132\n",
      "Negative Frequency: 0.0131\n",
      "contraction: 0.0128\n",
      "CEI_RollingMean: 0.0126\n",
      "LAG: 0.0100\n",
      "progressed: 0.0100\n",
      "Positive Frequency: 0.0091\n",
      "downgrade: 0.0087\n",
      "LEI_RollingMean: 0.0074\n",
      "Short-Term Treasury Diff: 0.0069\n",
      "cease: 0.0066\n",
      "weakening: 0.0062\n",
      "Retail Sales_RollingMean: 0.0054\n",
      "dismissed: 0.0054\n",
      "stabilized: 0.0045\n",
      "regain: 0.0043\n",
      "dropped: 0.0042\n",
      "breaching: 0.0037\n",
      "ill: 0.0034\n",
      "Durable Goods Orders: 0.0028\n",
      "cutback: 0.0026\n",
      "harmed: 0.0025\n",
      "depressing: 0.0021\n",
      "strain: 0.0019\n",
      "Proportion Negative Words: 0.0017\n",
      "LAG_RollingMean: 0.0015\n",
      "lacked: 0.0014\n",
      "lost: 0.0012\n",
      "Net Sentiment Score: 0.0012\n",
      "liquidation: 0.0012\n",
      "stringent: 0.0010\n",
      "ceased: 0.0010\n",
      "Durable Goods Orders_RollingMean: 0.0009\n",
      "unwanted: 0.0006\n",
      "intermittently: 0.0006\n",
      "dissented: 0.0006\n",
      "vulnerable: 0.0005\n",
      "depress: 0.0005\n",
      "adversely: 0.0003\n",
      "negative: 0.0003\n",
      "satisfactory: 0.0002\n",
      "diminished: 0.0001\n",
      "attain: 0.0001\n",
      "rebound: 0.0001\n",
      "weak: 0.0000\n",
      "severity: 0.0000\n",
      "sharply: 0.0000\n",
      "oppose: 0.0000\n",
      "layoff: 0.0000\n",
      "delayed: 0.0000\n",
      "persist: 0.0000\n",
      "threat: 0.0000\n",
      "Word Count: 0.0000\n",
      "aftermath: 0.0000\n",
      "attractive: 0.0000\n",
      "decline: 0.0000\n",
      "deterioration: 0.0000\n",
      "discrepancy: 0.0000\n",
      "easing: 0.0000\n",
      "encouragement: 0.0000\n",
      "excessive: 0.0000\n",
      "hardship: 0.0000\n",
      "harming: 0.0000\n",
      "impair: 0.0000\n",
      "impede: 0.0000\n",
      "improved: 0.0000\n",
      "inhibited: 0.0000\n",
      "markdown: 0.0000\n",
      "opportunity: 0.0000\n",
      "poor: 0.0000\n",
      "profitability: 0.0000\n",
      "quit: 0.0000\n",
      "sluggish: 0.0000\n",
      "stabilization: 0.0000\n",
      "standstill: 0.0000\n",
      "stopped: 0.0000\n",
      "stressing: 0.0000\n",
      "stronger: 0.0000\n",
      "susceptible: 0.0000\n",
      "unavailability: 0.0000\n",
      "unsold: 0.0000\n",
      "unsustainable: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importance\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "\n",
    "# Create a dictionary to map feature names to their importance scores\n",
    "feature_importance_dict = {feature_name: importance_score for feature_name, importance_score in zip(X_train.columns, feature_importance)}\n",
    "\n",
    "# Sort the feature importance dictionary in descending order based on importance scores\n",
    "sorted_feature_importance = dict(sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print the feature importance scores in descending order\n",
    "print(\"Feature Importance:\")\n",
    "for feature_name, importance_score in sorted_feature_importance.items():\n",
    "    print(f\"{feature_name}: {importance_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5e51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features with importance greater than 0.01\n",
    "selected_features = [feature_name for feature_name, importance_score in feature_importance_dict.items() if importance_score > 0.01]\n",
    "\n",
    "# Create new datasets with selected features\n",
    "selected_X_train = X_train[selected_features]\n",
    "selected_X_valid = X_valid[selected_features]\n",
    "\n",
    "# Initialize and train the XGBoost model with the selected features\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(selected_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set with the selected features\n",
    "y_train_pred = xgb_model.predict(selected_X_train)\n",
    "\n",
    "# Make predictions on the validation set with the selected features\n",
    "y_valid_pred = xgb_model.predict(selected_X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524e74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0598958 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.244736  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.0784641 |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.2826    |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.5       |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7635",
   "metadata": {},
   "source": [
    "###Elastic Net Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f3cb56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+00, tolerance: 7.687e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+00, tolerance: 7.687e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Create the Elastic Net Regression model\n",
    "elastic_net_model = ElasticNet(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 4, 9),   # Range of alpha values (regularization strength)\n",
    "    'l1_ratio': np.linspace(0, 1, 11)  # Range of l1_ratio values (mixing parameter between L1 and L2 penalties)\n",
    "}\n",
    "\n",
    "# Create GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=elastic_net_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data and find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "\n",
    "# Initialize the Elastic Net Regression model with the best hyperparameters\n",
    "best_elastic_net_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, random_state=42)\n",
    "\n",
    "# Fit the model to the training data with the best hyperparameters\n",
    "best_elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = best_elastic_net_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = best_elastic_net_model.predict(X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "855c5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |      0.0276693 |        0.0703125 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |      0.166341  |        0.265165  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |      0.308914  |       -0.081803  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |     -0.419328  |        1.33175   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |      0.75      |        0.541667  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
