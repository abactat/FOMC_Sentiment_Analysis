{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d5074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from mord import OrdinalRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419d59cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and loaded into 'train' successfully.\n",
      "Dataset downloaded and loaded into 'valid' successfully.\n",
      "Dataset downloaded and loaded into 'test' successfully.\n"
     ]
    }
   ],
   "source": [
    "# The URL of the raw dataset on GitHub\n",
    "url = \"https://raw.githubusercontent.com/abactat/BC-Project/main/data/processed/train_data.csv?token=GHSAT0AAAAAACC4ZCNLK5WDAXMHGAA2JI24ZGGSK4A\"\n",
    "\n",
    "# Send an HTTP GET request to fetch the content of the raw dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200 means success)\n",
    "if response.status_code == 200:\n",
    "    # Read the content as a pandas DataFrame and assign it to the 'train' variable\n",
    "    train = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Dataset downloaded and loaded into 'train' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")\n",
    "    \n",
    "# The URL of the raw dataset on GitHub\n",
    "url = \"https://raw.githubusercontent.com/abactat/BC-Project/main/data/processed/val_data.csv?token=GHSAT0AAAAAACC4ZCNK6U7OS5YW72PK3GBSZGGSH2A\"\n",
    "\n",
    "# Send an HTTP GET request to fetch the content of the raw dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200 means success)\n",
    "if response.status_code == 200:\n",
    "    # Read the content as a pandas DataFrame and assign it to the 'valid' variable\n",
    "    valid = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Dataset downloaded and loaded into 'valid' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")\n",
    "    \n",
    "# The URL of the raw dataset on GitHub\n",
    "url = \"https://raw.githubusercontent.com/abactat/BC-Project/main/data/processed/test_data.csv?token=GHSAT0AAAAAACC4ZCNL45CUOECJPHCIM43GZGGSIGQ\"\n",
    "\n",
    "# Send an HTTP GET request to fetch the content of the raw dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200 means success)\n",
    "if response.status_code == 200:\n",
    "    # Read the content as a pandas DataFrame and assign it to the 'train' variable\n",
    "    test = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Dataset downloaded and loaded into 'test' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b9863",
   "metadata": {},
   "source": [
    "###Preprocess the data with variables, and function for converting predicted values into magnitude of 25 basis points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e3334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert variables to numeric in the train dataset\n",
    "variables_to_convert = train.columns.drop('Date')\n",
    "train[variables_to_convert] = train[variables_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert variables to numeric in the valid dataset\n",
    "valid[variables_to_convert] = valid[variables_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Prepare the data for the model\n",
    "X_train = train.drop(columns=['Difference', 'Increase', 'Decrease', 'Date'])\n",
    "y_train = train['Difference']  # Use the 'Difference' variable as the target\n",
    "\n",
    "X_valid = valid.drop(columns=['Difference', 'Increase', 'Decrease', 'Date'])\n",
    "y_valid = valid['Difference']  # Use the 'Difference' variable as the target\n",
    "\n",
    "possible_values = [-1.00, -0.75, -0.50, -0.25, 0.00, 0.25, 0.50, 0.75, 1.00]\n",
    "\n",
    "def round_to_nearest(value, possible_values):\n",
    "    return min(possible_values, key=lambda x: abs(x - value))\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(y_true)\n",
    "    \n",
    "    for true_val, pred_val in zip(y_true, y_pred):\n",
    "        if true_val == pred_val:\n",
    "            correct_predictions += 1\n",
    "            \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a4c64",
   "metadata": {},
   "source": [
    "###Ordinal Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9096d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and scale the independent variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Initialize and train the ordinal logistic regression model\n",
    "ordinal_model = OrdinalRidge()\n",
    "ordinal_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = ordinal_model.predict(X_valid_scaled)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = ordinal_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af368b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |      0.0373037 |        0.0729167 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |      0.193142  |        0.270031  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |      0.0731313 |       -0.12187   |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |     -0.834428  |        1.36342   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |      0.706806  |        0.583333  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438c762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and scale the independent variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Initialize and train the ordinal logistic regression model\n",
    "ordinal_model = OrdinalRidge()\n",
    "ordinal_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = ordinal_model.predict(X_valid_scaled)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = ordinal_model.predict(X_train_scaled)\n",
    "\n",
    "# Get the initial model performance (MSE) on the validation set\n",
    "best_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Initialize the list of selected features with all features\n",
    "selected_features = list(range(X_train_scaled.shape[1]))\n",
    "\n",
    "# Perform reverse variable selection\n",
    "while len(selected_features) > 1:\n",
    "    # Store the current MSE and feature to be removed\n",
    "    current_best_mse = best_mse\n",
    "    feature_to_remove = None\n",
    "    \n",
    "    # Iterate over each feature and remove one at a time\n",
    "    for feature in selected_features:\n",
    "        # Create a copy of the selected features with the current feature removed\n",
    "        reduced_X_train_scaled = np.delete(X_train_scaled, feature, axis=1)\n",
    "        reduced_X_valid_scaled = np.delete(X_valid_scaled, feature, axis=1)\n",
    "        \n",
    "        # Initialize and train the ordinal logistic regression model with the reduced features\n",
    "        ordinal_model = OrdinalRidge()\n",
    "        ordinal_model.fit(reduced_X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions on the validation set with the reduced features\n",
    "        y_valid_pred = ordinal_model.predict(reduced_X_valid_scaled)\n",
    "        \n",
    "        # Calculate the MSE with the reduced features\n",
    "        mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "        \n",
    "        # Check if the model performance has improved\n",
    "        if mse < current_best_mse:\n",
    "            current_best_mse = mse\n",
    "            feature_to_remove = feature\n",
    "            \n",
    "    # If removing a feature improves the model performance, update the selected features and best MSE\n",
    "    if feature_to_remove is not None:\n",
    "        selected_features.remove(feature_to_remove)\n",
    "        best_mse = current_best_mse\n",
    "    else:\n",
    "        # No feature was removed, exit the loop\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44a0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'selected_features' contains the list of best selected features\n",
    "selected_X_train = X_train_scaled[:, selected_features]\n",
    "selected_X_valid = X_valid_scaled[:, selected_features]\n",
    "\n",
    "# Initialize and train the XGBoost model with the best selected features\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(selected_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set with the best selected features\n",
    "y_train_pred = xgb_model.predict(selected_X_train)\n",
    "\n",
    "# Make predictions on the validation set with the best selected features\n",
    "y_valid_pred = xgb_model.predict(selected_X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a77236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0208333 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.144338  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.679466  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.10384   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.666667  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = selected_X_train.shape[0]\n",
    "p_train = selected_X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad606c7",
   "metadata": {},
   "source": [
    "###XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5cd80",
   "metadata": {},
   "source": [
    "###All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d69654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = xgb_model.predict(X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c98480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in selected_features: 191\n"
     ]
    }
   ],
   "source": [
    "num_variables = len(X_train)\n",
    "print(\"Number of variables in selected_features:\", num_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c1aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0208333 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.144338  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.679466  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.10384   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.666667  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd1a915",
   "metadata": {},
   "source": [
    "###Reverse Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e78e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Score: 0.6918644536010811\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Evaluate initial model performance\n",
    "initial_model_score = xgb_model.score(X_valid, y_valid)\n",
    "best_model_score = initial_model_score\n",
    "best_model = xgb_model\n",
    "\n",
    "# Step 2 to 6: Reverse variable selection loop\n",
    "selected_features = list(X_train.columns)  # Assuming X_train is a DataFrame\n",
    "for feature in X_train.columns:\n",
    "    # Temporarily remove the feature\n",
    "    X_train_subset = X_train.drop(feature, axis=1)\n",
    "    X_valid_subset = X_valid.drop(feature, axis=1)\n",
    "    \n",
    "    # Retrain the model without the removed feature\n",
    "    xgb_model_subset = xgb.XGBRegressor()\n",
    "    xgb_model_subset.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Evaluate the model performance on the validation set\n",
    "    model_score = xgb_model_subset.score(X_valid_subset, y_valid)\n",
    "    \n",
    "    # Check if the model performance improved\n",
    "    if model_score > best_model_score:\n",
    "        best_model_score = model_score\n",
    "        best_model = xgb_model_subset\n",
    "        selected_features.remove(feature)\n",
    "print(\"Best Model Score:\", best_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c34ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in selected_features: 93\n"
     ]
    }
   ],
   "source": [
    "num_variables = len(selected_features)\n",
    "print(\"Number of variables in selected_features:\", num_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5560b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'selected_features' contains the list of best selected features\n",
    "selected_X_train = X_train[selected_features]\n",
    "selected_X_valid = X_valid[selected_features]\n",
    "\n",
    "# Initialize and train the XGBoost model with the best selected features\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(selected_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set with the best selected features\n",
    "y_train_pred = xgb_model.predict(selected_X_train)\n",
    "\n",
    "# Make predictions on the validation set with the best selected features\n",
    "y_valid_pred = xgb_model.predict(selected_X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c77fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |        0.0208333 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |        0.144338  |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |        0.679466  |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |        1.10384   |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |        0.666667  |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f480f5",
   "metadata": {},
   "source": [
    "###Variable selection, greater than 0.01 feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef660e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "Standardized Sentiment Score: 0.3552\n",
      "uncertain: 0.1069\n",
      "LEI: 0.0602\n",
      "assumed: 0.0505\n",
      "Negative Frequency: 0.0367\n",
      "might: 0.0316\n",
      "Durable Goods Orders: 0.0293\n",
      "anticipated: 0.0287\n",
      "could: 0.0270\n",
      "easier: 0.0244\n",
      "LAG: 0.0226\n",
      "believed: 0.0210\n",
      "LEI_RollingMean: 0.0209\n",
      "Short-Term Treasury Bond Rate: 0.0174\n",
      "depend: 0.0125\n",
      "regain: 0.0121\n",
      "Level: 0.0115\n",
      "Long-Term Treasury Bond Rate: 0.0107\n",
      "prosperity: 0.0094\n",
      "CPI: 0.0089\n",
      "bolstering: 0.0082\n",
      "gaining: 0.0073\n",
      "apparent: 0.0068\n",
      "appeared: 0.0064\n",
      "attain: 0.0062\n",
      "Bank Reserves: 0.0058\n",
      "Net Sentiment Score: 0.0055\n",
      "cautiously: 0.0055\n",
      "encouragement: 0.0050\n",
      "unknown: 0.0042\n",
      "attractiveness: 0.0041\n",
      "opportunity: 0.0039\n",
      "positive: 0.0037\n",
      "Retail Sales: 0.0035\n",
      "risk: 0.0029\n",
      "Retail Sales_RollingMean: 0.0027\n",
      "suggested: 0.0026\n",
      "stabilization: 0.0023\n",
      "strengthening: 0.0018\n",
      "apparently: 0.0017\n",
      "Short-Term Treasury Diff: 0.0016\n",
      "Unemployment Rate: 0.0015\n",
      "volatile: 0.0014\n",
      "optimistic: 0.0013\n",
      "Average Hourly Earnings: 0.0009\n",
      "unclear: 0.0009\n",
      "better: 0.0008\n",
      "uncertainty: 0.0007\n",
      "rebound: 0.0006\n",
      "profitability: 0.0005\n",
      "Positive Frequency: 0.0005\n",
      "stabilized: 0.0004\n",
      "leading: 0.0003\n",
      "CEI_RollingMean: 0.0003\n",
      "good: 0.0002\n",
      "vary: 0.0002\n",
      "nearly: 0.0001\n",
      "stable: 0.0001\n",
      "sudden: 0.0001\n",
      "improved: 0.0001\n",
      "cautious: 0.0000\n",
      "tremendous: 0.0000\n",
      "LAG_RollingMean: 0.0000\n",
      "Treasury Deposits: 0.0000\n",
      "roughly: 0.0000\n",
      "CEI: 0.0000\n",
      "possibility: 0.0000\n",
      "anticipating: 0.0000\n",
      "Durable Goods Orders_RollingMean: 0.0000\n",
      "almost: 0.0000\n",
      "appearing: 0.0000\n",
      "satisfactory: 0.0000\n",
      "Word Count: 0.0000\n",
      "assumption: 0.0000\n",
      "attractive: 0.0000\n",
      "bolstered: 0.0000\n",
      "favorable: 0.0000\n",
      "improvement: 0.0000\n",
      "possibly: 0.0000\n",
      "presumed: 0.0000\n",
      "progress: 0.0000\n",
      "progressed: 0.0000\n",
      "rebounded: 0.0000\n",
      "rebounding: 0.0000\n",
      "smooth: 0.0000\n",
      "sometime: 0.0000\n",
      "stronger: 0.0000\n",
      "strongest: 0.0000\n",
      "succeeded: 0.0000\n",
      "suggesting: 0.0000\n",
      "surpassing: 0.0000\n",
      "unexpected: 0.0000\n",
      "upturn: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importance\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "\n",
    "# Create a dictionary to map feature names to their importance scores\n",
    "feature_importance_dict = {feature_name: importance_score for feature_name, importance_score in zip(X_train.columns, feature_importance)}\n",
    "\n",
    "# Sort the feature importance dictionary in descending order based on importance scores\n",
    "sorted_feature_importance = dict(sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print the feature importance scores in descending order\n",
    "print(\"Feature Importance:\")\n",
    "for feature_name, importance_score in sorted_feature_importance.items():\n",
    "    print(f\"{feature_name}: {importance_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5e51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features with importance greater than 0.01\n",
    "selected_features = [feature_name for feature_name, importance_score in feature_importance_dict.items() if importance_score > 0.01]\n",
    "\n",
    "# Create new datasets with selected features\n",
    "selected_X_train = X_train[selected_features]\n",
    "selected_X_valid = X_valid[selected_features]\n",
    "\n",
    "# Initialize and train the XGBoost model with the selected features\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(selected_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set with the selected features\n",
    "y_train_pred = xgb_model.predict(selected_X_train)\n",
    "\n",
    "# Make predictions on the validation set with the selected features\n",
    "y_valid_pred = xgb_model.predict(selected_X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524e74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |              0 |         0.046875 |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |              0 |         0.216506 |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |              1 |         0.278798 |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |              1 |         1.23363  |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |              1 |         0.375    |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7635",
   "metadata": {},
   "source": [
    "###Elastic Net Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f3cb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Elastic Net Regression model\n",
    "elastic_net_model = ElasticNet(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 4, 9),   # Range of alpha values (regularization strength)\n",
    "    'l1_ratio': np.linspace(0, 1, 11)  # Range of l1_ratio values (mixing parameter between L1 and L2 penalties)\n",
    "}\n",
    "\n",
    "# Create GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=elastic_net_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data and find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "\n",
    "# Initialize the Elastic Net Regression model with the best hyperparameters\n",
    "best_elastic_net_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, random_state=42)\n",
    "\n",
    "# Fit the model to the training data with the best hyperparameters\n",
    "best_elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = best_elastic_net_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred = best_elastic_net_model.predict(X_valid)\n",
    "\n",
    "# Example usage for y_train_pred\n",
    "y_train_pred = [round_to_nearest(pred, possible_values) for pred in y_train_pred]\n",
    "\n",
    "# Example usage for y_valid_pred\n",
    "y_valid_pred = [round_to_nearest(pred, possible_values) for pred in y_valid_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "855c5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+------------------+\n",
      "| Metric       |   Training Set |   Validation Set |\n",
      "+==============+================+==================+\n",
      "| MSE          |    0.0402487   |       0.0651042  |\n",
      "+--------------+----------------+------------------+\n",
      "| RMSE         |    0.200621    |       0.255155   |\n",
      "+--------------+----------------+------------------+\n",
      "| R^2          |   -4.25677e-05 |      -0.00166945 |\n",
      "+--------------+----------------+------------------+\n",
      "| Adjusted R^2 |   -0.979251    |       1.32448    |\n",
      "+--------------+----------------+------------------+\n",
      "| Accuracy     |    0.701571    |       0.583333   |\n",
      "+--------------+----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for training set\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for validation set\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Calculate R-squared (R^2) for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R-squared (R^2) for validation set\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "n_train = X_train.shape[0]\n",
    "p_train = X_train.shape[1]\n",
    "adj_r2_train = 1 - ((1 - r2_train) * (n_train - 1) / (n_train - p_train - 1))\n",
    "\n",
    "# Calculate adjusted R-squared for validation set\n",
    "n_valid = X_valid.shape[0]\n",
    "p_valid = X_valid.shape[1]\n",
    "adj_r2_valid = 1 - ((1 - r2_valid) * (n_valid - 1) / (n_valid - p_valid - 1))\n",
    "\n",
    "# Calculate accuracy for training and validation sets\n",
    "accuracy_train = calculate_accuracy(y_train, y_train_pred)\n",
    "accuracy_valid = calculate_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# Prepare the data for the table\n",
    "data = [\n",
    "    [\"MSE\", mse_train, mse_valid],\n",
    "    [\"RMSE\", rmse_train, rmse_valid],\n",
    "    [\"R^2\", r2_train, r2_valid],\n",
    "    [\"Adjusted R^2\", adj_r2_train, adj_r2_valid],\n",
    "    [\"Accuracy\", accuracy_train, accuracy_valid],\n",
    "]\n",
    "\n",
    "# Prepare the headers for the table\n",
    "headers = [\"Metric\", \"Training Set\", \"Validation Set\"]\n",
    "\n",
    "# Display the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
